<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fast Voice Stream</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 20px;
        }
        select, button {
            padding: 12px 24px;
            font-size: 16px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        select {
            background-color: #fff;
            border: 1px solid #ddd;
            min-width: 150px;
        }
        button {
            background-color: #4CAF50;
            color: white;
            font-weight: 500;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #stopStream {
            background-color: #f44336;
        }
        #status {
            text-align: center;
            margin: 10px 0;
            color: #666;
        }
        .transcription-container {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 20px;
            height: 300px;
            overflow-y: auto;
            font-size: 18px;
            line-height: 1.6;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        .voice-info {
            text-align: center;
            margin: 10px 0;
            color: #666;
            font-size: 14px;
        }
        .error-message {
            color: #f44336;
            text-align: center;
            margin: 10px 0;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Fast Voice Stream</h1>
        
        <div class="controls">
            <select id="languageSelect">
                <option value="en">English</option>
                <option value="es">Spanish</option>
                <option value="pt">Portuguese</option>
            </select>
            <button id="startStream">Start Stream</button>
            <button id="stopStream" disabled>Stop Stream</button>
        </div>

        <div id="status">Ready to start</div>
        <div id="errorMessage" class="error-message"></div>
        <div id="voiceInfo" class="voice-info"></div>
        <div id="transcriptionContainer" class="transcription-container"></div>
    </div>

    <script>
        class AudioRecorder {
            constructor() {
                this.mediaRecorder = null;
                this.audioChunks = [];
                this.isRecording = false;
                this.stream = null;
            }

            async startRecording() {
                try {
                    this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    this.mediaRecorder = new MediaRecorder(this.stream);
                    this.audioChunks = [];
                    this.isRecording = true;

                    this.mediaRecorder.ondataavailable = async (event) => {
                        if (event.data.size > 0) {
                            // Convert blob to base64
                            const reader = new FileReader();
                            reader.readAsDataURL(event.data);
                            reader.onloadend = async () => {
                                const base64Audio = reader.result;
                                await this.processAudioChunk(base64Audio);
                            };
                        }
                    };

                    this.mediaRecorder.start(1000); // Collect 1 second of audio at a time
                    return true;
                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    throw error;
                }
            }

            stopRecording() {
                if (this.mediaRecorder && this.isRecording) {
                    this.mediaRecorder.stop();
                    this.stream.getTracks().forEach(track => track.stop());
                    this.isRecording = false;
                }
            }

            async processAudioChunk(base64Audio) {
                try {
                    const response = await fetch('/process_audio', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({ audio: base64Audio })
                    });

                    if (!response.ok) {
                        throw new Error('Failed to process audio');
                    }

                    const result = await response.json();
                    if (result.text) {
                        handleTranscription(result.text, true);
                    }
                } catch (error) {
                    console.error('Error processing audio:', error);
                    errorMessage.textContent = error.message;
                    setTimeout(() => {
                        errorMessage.textContent = '';
                    }, 3000);
                }
            }
        }

        const startButton = document.getElementById('startStream');
        const stopButton = document.getElementById('stopStream');
        const status = document.getElementById('status');
        const errorMessage = document.getElementById('errorMessage');
        const transcriptionContainer = document.getElementById('transcriptionContainer');
        const voiceInfo = document.getElementById('voiceInfo');
        const languageSelect = document.getElementById('languageSelect');

        let audioRecorder = new AudioRecorder();
        let translationEventSource = null;
        let synth = window.speechSynthesis;
        let isSpeaking = false;
        let currentAudio = null;
        let lastSpokenText = '';

        function generateUUID() {
            return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
                const r = Math.random() * 16 | 0;
                return (c === 'x' ? r : (r & 0x3 | 0x8)).toString(16);
            });
        }

        const clientId = generateUUID();

        async function stopAllSpeech() {
            if (currentAudio) {
                currentAudio.pause();
                currentAudio.currentTime = 0;
                currentAudio = null;
            }
            synth.cancel();
            isSpeaking = false;
        }

        function updateVoiceInfo() {
            const selectedLanguage = languageSelect.value;
            if (selectedLanguage === 'pt') {
                voiceInfo.textContent = 'Using Microsoft Azure pt-BR-AntonioNeural voice';
            } else if (selectedLanguage === 'es') {
                voiceInfo.textContent = 'Using Microsoft Azure es-ES-AlvaroNeural voice';
            } else {
                voiceInfo.textContent = 'Using system default voice';
            }
        }

        async function speakText(text) {
            if (!text.trim() || text === lastSpokenText || isSpeaking) return;
            lastSpokenText = text;

            try {
                await stopAllSpeech();
                isSpeaking = true;

                const language = languageSelect.value;
                
                if (language === 'pt' || language === 'es') {
                    const response = await fetch('/synthesize_speech', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            text: text,
                            language: language
                        })
                    });

                    if (!response.ok) {
                        throw new Error('Speech synthesis failed');
                    }

                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);

                    return new Promise((resolve, reject) => {
                        const audio = new Audio(audioUrl);
                        currentAudio = audio;

                        const cleanupAudio = () => {
                            URL.revokeObjectURL(audioUrl);
                            currentAudio = null;
                            isSpeaking = false;
                        };

                        audio.onended = () => {
                            cleanupAudio();
                            resolve();
                        };

                        audio.onerror = (error) => {
                            cleanupAudio();
                            reject(error);
                        };

                        audio.play().catch(error => {
                            cleanupAudio();
                            reject(error);
                        });
                    });
                } else {
                    return new Promise((resolve, reject) => {
                        const utterance = new SpeechSynthesisUtterance(text);
                        utterance.lang = language;
                        
                        utterance.onend = () => {
                            isSpeaking = false;
                            resolve();
                        };
                        
                        utterance.onerror = (event) => {
                            isSpeaking = false;
                            reject(event);
                        };
                        
                        synth.speak(utterance);
                    });
                }
            } catch (error) {
                console.error('Speech error:', error);
                isSpeaking = false;
                errorMessage.textContent = `Error during speech synthesis: ${error.message}`;
                setTimeout(() => {
                    errorMessage.textContent = '';
                }, 3000);
            }
        }

        function connectTranslationStream(targetLanguage) {
            if (translationEventSource) {
                translationEventSource.close();
            }

            const baseUrl = window.location.protocol + '//' + window.location.host;
            translationEventSource = new EventSource(`${baseUrl}/stream_translation/${targetLanguage}?client_id=${clientId}`);
            let lastTranslation = '';

            translationEventSource.onmessage = async (event) => {
                try {
                    const data = JSON.parse(event.data);
                    if (!data.keepalive) {
                        if (data.type === 'partial') {
                            transcriptionContainer.textContent = data.translation;
                        } else if (data.type === 'final' && data.translation) {
                            if (data.translation !== lastTranslation) {
                                transcriptionContainer.textContent = data.translation;
                                lastTranslation = data.translation;
                                await speakText(data.translation);
                            }
                        }
                    }
                } catch (error) {
                    console.error('Translation processing error:', error);
                }
            };

            translationEventSource.onerror = () => {
                errorMessage.textContent = 'Translation connection lost. Reconnecting...';
                translationEventSource.close();
                setTimeout(() => connectTranslationStream(targetLanguage), 2000);
            };
        }

        function handleTranscription(text, isFinal) {
            const targetLanguage = languageSelect.value;
            if (targetLanguage === 'en') {
                transcriptionContainer.textContent = text;
                if (isFinal) {
                    speakText(text);
                }
            } else {
                fetch('/translate_realtime', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        text: text,
                        targetLanguage: targetLanguage,
                        clientId: clientId,
                        isFinal: isFinal
                    })
                }).catch(error => {
                    console.error('Translation error:', error);
                    errorMessage.textContent = 'Error processing translation';
                    setTimeout(() => {
                        errorMessage.textContent = '';
                    }, 2000);
                });
            }
        }

        async function startStreaming() {
            try {
                errorMessage.textContent = '';
                await stopAllSpeech();
                lastSpokenText = '';

                await audioRecorder.startRecording();
                
                startButton.disabled = true;
                stopButton.disabled = false;
                status.textContent = 'Streaming...';
                transcriptionContainer.textContent = '';

                const targetLanguage = languageSelect.value;
                if (targetLanguage !== 'en') {
                    connectTranslationStream(targetLanguage);
                }
            } catch (error) {
                status.textContent = 'Error starting stream';
                errorMessage.textContent = error.message;
                console.error(error);
            }
        }

        function stopStreaming() {
            audioRecorder.stopRecording();
            startButton.disabled = false;
            stopButton.disabled = true;
            
            if (translationEventSource) {
                translationEventSource.close();
                translationEventSource = null;
            }
            
            transcriptionContainer.textContent = '';
            status.textContent = 'Stopped';
            errorMessage.textContent = '';
            stopAllSpeech();
            lastSpokenText = '';
        }

        startButton.addEventListener('click', startStreaming);
        stopButton.addEventListener('click', stopStreaming);

        languageSelect.addEventListener('change', async () => {
            const targetLanguage = languageSelect.value;
            transcriptionContainer.textContent = '';
            errorMessage.textContent = '';
            await stopAllSpeech();
            lastSpokenText = '';
            updateVoiceInfo();

            if (translationEventSource) {
                translationEventSource.close();
                translationEventSource = null;
            }

            if (startButton.disabled && targetLanguage !== 'en') {
                setTimeout(() => connectTranslationStream(targetLanguage), 100);
            }
        });

        document.addEventListener('DOMContentLoaded', () => {
            updateVoiceInfo();
        });

        window.addEventListener('beforeunload', () => {
            if (translationEventSource) {
                translationEventSource.close();
            }
            audioRecorder.stopRecording();
            stopAllSpeech();
        });
    </script>
</body>
</html>